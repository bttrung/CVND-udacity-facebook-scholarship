## RNN's


### Definitions
- RNN: Recurrent Neural Networks - give us a way to incorporate memory into our neural networks, and will be critical in analyzing sequential data
- FFNN: Feedfoward Neural Network
- Vanishing Gradient

- Feedforward
- Backpropagation
- MSE: Mean Squared Error
- Cross Entropy
- Activation function

### References
- [Video Classification Method](https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5af0e03b_video-classification/video-classification.pdf)
- [Sketch RNN](https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html)
- [Vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem)
- [Time Delay Neural Network](https://en.wikipedia.org/wiki/Time_delay_neural_network)
- [MSE](https://en.wikipedia.org/wiki/Mean_squared_error)
- [ReLU and Softmax Activation Functions](https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions)
